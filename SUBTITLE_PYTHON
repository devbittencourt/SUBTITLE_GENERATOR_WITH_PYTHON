
import speech_recognition as sr
import moviepy.editor as mp
import cv2
import os
import tkinter as tk
from tkinter import filedialog

VEL = 14-2  # float(input("Por favor, insira a velocidade da legenda (em palavras por minuto): "))
NIVEL = 250  # float(input("Por favor, insira a velocidade da legenda (em palavras por minuto): "))
def transcribe_audio(audio_file):
    recognizer = sr.Recognizer()

    with sr.AudioFile(audio_file) as source:
        audio = recognizer.record(source)

    try:
        transcript = recognizer.recognize_google(audio, language='pt-BR')  # Altere o idioma conforme necessário
        return transcript
    except sr.UnknownValueError:
        print("Não foi possível reconhecer a fala")
        return ""
    except sr.RequestError as e:
        print("Erro ao recuperar resultados; {0}".format(e))
        return ""


def extract_audio(video_file):
    video = mp.VideoFileClip(video_file)
    audio_file = "audio.wav"
    video.audio.write_audiofile(audio_file)
    return audio_file


def add_subtitles(video_file, subtitles):
    video = cv2.VideoCapture(video_file)
    fps = video.get(cv2.CAP_PROP_FPS)
    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    output_video = cv2.VideoWriter("subtitled_video.mp4", fourcc, fps, (frame_width, frame_height))

    font = cv2.FONT_HERSHEY_COMPLEX_SMALL
    font_scale = 2.1
    font_color = (0, 0, 0)  # Cor da sombra
    thickness = 3

    current_frame = 0

    for i, (subtitle, subtitle_duration) in enumerate(subtitles):
        next_subtitle = subtitles[i + 1][0] if i < len(subtitles) - 1 else None

        text_size_current, _ = cv2.getTextSize(subtitle, font, font_scale, thickness)
        text_size_next, _ = cv2.getTextSize(next_subtitle, font, font_scale, thickness) if next_subtitle else (0, 0)

        text_x_current = (frame_width - text_size_current[0] - 140) // 2
        text_y_current = (frame_height + text_size_current[1]+ NIVEL) // 2
        text_x_next = (frame_width - text_size_next[0] + 140) // 2 if next_subtitle else 0
        text_y_next = (frame_height + text_size_next[1]+ NIVEL) // 2 if next_subtitle else 0

        for _ in range(int(subtitle_duration * fps / VEL)):
            ret, frame = video.read()
            if not ret:
                break

            # Adiciona a sombra
            cv2.putText(frame, subtitle, (text_x_current + 2, text_y_current + 2), font, font_scale, font_color, thickness)

            # Adiciona o texto principal
            cv2.putText(frame, subtitle, (text_x_current, text_y_current), font, font_scale, (0, 255, 0), thickness)

            if next_subtitle:
                # Adiciona a sombra para a próxima legenda
                cv2.putText(frame, next_subtitle, (text_x_next + 2, text_y_next + 2), font, font_scale, font_color, thickness)

                # Adiciona o texto principal para a próxima legenda
                cv2.putText(frame, next_subtitle, (text_x_next, text_y_next), font, font_scale, (0, 255, 0), thickness)

            output_video.write(frame)
            current_frame += 1

    video.release()
    output_video.release()


def combine_audio_and_video(video_file, audio_file, output_file):
    video = mp.VideoFileClip(video_file)
    audio = mp.AudioFileClip(audio_file)

    video = video.set_audio(audio)
    video.write_videofile(output_file, codec='libx264')


def select_videos():
    root = tk.Tk()
    root.withdraw()
    file_paths = filedialog.askopenfilenames(filetypes=[("Video files", "*.mp4")])
    return file_paths


def main():
    video_files = select_videos()

    for video_file in video_files:
        audio_file = extract_audio(video_file)

        # Transcreve o áudio
        transcript = transcribe_audio(audio_file)

        if transcript:
            # Divide o texto em legendas de tamanho gerenciável
            subtitle_duration = 5  # Duração de cada legenda em segundos
            subtitles = [(transcript[i:i + subtitle_duration], subtitle_duration) for i in
                         range(0, len(transcript), subtitle_duration)]

            # Adiciona as legendas ao vídeo
            add_subtitles(video_file, subtitles)

            # Obtém o diretório do arquivo inicial
            output_directory = os.path.dirname(video_file)

            # Gera um nome de arquivo de saída único
            output_file = os.path.join(output_directory, "subtitled_" + os.path.basename(video_file))

            # Combina áudio e vídeo
            combine_audio_and_video("subtitled_video.mp4", audio_file, output_file)

            print(f"Legendas adicionadas e áudio combinado com sucesso para {video_file}.")
            os.remove("subtitled_video.mp4")  # Remover vídeo intermediário
        else:
            print(f"Não foi possível transcrever o áudio para {video_file}.")

    print("Processamento concluído para todos os vídeos selecionados.")


if __name__ == "__main__":
    main()
